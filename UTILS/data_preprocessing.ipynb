{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime \n",
    "\n",
    "def pad_nans(df):\n",
    "    for j, col in enumerate(df.columns):\n",
    "        for i in range(df.shape[0]):\n",
    "            if pd.isna(df.iloc[i,j]):\n",
    "                df.iloc[i,j] = (df.iloc[i-1,j]+df.iloc[i+1,j])/2\n",
    "                #print(j, i, col, df.iloc[i,j])\n",
    "    return df;\n",
    "\n",
    "def set_timestamp_as_index(source_df, ts_format = '%Y/%m/%d %H:%M:%S.%f'):\n",
    "    target_df = source_df.iloc[:, 2:];\n",
    "    # df_ts=list(map(lambda x: x.split('.')[0], source_df['Timestamp'].values));\n",
    "    df_ts=pd.to_datetime(df_ts, format=ts_format);\n",
    "    target_df.index = df_ts;\n",
    "    return target_df;\n",
    "\n",
    "def build_histogram(column_values, bins_count):\n",
    "    min_val = np.min(column_values);\n",
    "    max_val = np.max(column_values); \n",
    "    step = (max_val - min_val) / bins_count;\n",
    "    bins = np.arange(min_val, max_val, step);\n",
    "    return np.histogram(column_values, bins);\n",
    "\n",
    "def determine_data_range(column_values, valid_data_percent = 95):\n",
    "    bins_count = 100;\n",
    "    samples_count = len(column_values);\n",
    "    hist, bins = build_histogram(column_values, bins_count);\n",
    "    \n",
    "    median = np.median(column_values);\n",
    "    min_id = 0; \n",
    "    max_id = -1;\n",
    "    min_val = bins[0];\n",
    "    max_val = bins[-1]; \n",
    "    non_valid_points = 0;\n",
    "    non_valid_points_max_count = samples_count * (100 - valid_data_percent) / 100;\n",
    "    \n",
    "    while(non_valid_points < non_valid_points_max_count):\n",
    "        med_max = max_val - median;\n",
    "        min_med = median - min_val;\n",
    "        if(med_max < min_med):\n",
    "            non_valid_points += hist[min_id];\n",
    "            min_id += 1;\n",
    "            min_val = bins[min_id];\n",
    "        else:\n",
    "            non_valid_points += hist[max_id];\n",
    "            max_id -= 1;\n",
    "            max_val = bins[max_id];\n",
    "    return min_val, max_val, hist, bins;\n",
    "    \n",
    "def drop_peaks(column_values, min_val, max_val):\n",
    "    result_values = []\n",
    "    for row, value in enumerate(column_values):\n",
    "        if (value < min_val) or (value > max_val):\n",
    "            result_values.append(np.NaN)\n",
    "            print('replasing row', row, ' value', value)    \n",
    "        else: \n",
    "            result_values.append(value)\n",
    "    return result_values\n",
    "\n",
    "def get_stationary_variance(df_col, window_size):\n",
    "    mean = np.convolve(df_col, np.ones(window_size)/window_size, mode=\"same\");\n",
    "    noise = (df_col - mean);\n",
    "    variance = np.sqrt(np.power(noise[window_size:-window_size], 2).mean());\n",
    "    return variance, mean, noise\n",
    "\n",
    "def get_variance(df_col):\n",
    "    mean = df_col.values.mean();\n",
    "    noise = (df_col - mean);\n",
    "    variance = np.sqrt(np.power(noise, 2).mean());\n",
    "    return variance, mean, noise\n",
    "\n",
    "def group_collect_statistics(dfs_groups):\n",
    "    df_statistics = pd.DataFrame();\n",
    "    row = 0;\n",
    "    for k, v in dfs_groups.items():\n",
    "        l = pd.concat(map(get_single_segment_statistics, v))\n",
    "        seg = v[0]['Current segment'].values[0];\n",
    "        df_statistics.loc[row,'Segment'] = seg;\n",
    "        df_statistics.loc[row,'Duration'] = l.Duration.mean();\n",
    "        df_statistics.loc[row,'Duration Variance'] = get_variance(l.Duration)[1];\n",
    "        df_statistics.loc[row,'Samples count'] = l['Samples count'].mean()\n",
    "        vr, mn, n = get_variance(l['Voltage delta']);\n",
    "        df_statistics.loc[row,'Voltage delta'] = l['Voltage delta'].mean();\n",
    "        df_statistics.loc[row,'Voltage delta variance'] = vr;\n",
    "        df_statistics.loc[row,'Mass'] =l['Mass'].mean() \n",
    "        row += 1\n",
    "    return df_statistics\n",
    "\n",
    "def fix_bad_column_samples(df_col, window_size, sigmas_k):\n",
    "    df_col_res = df_col.copy();\n",
    "    variance, mean, noise = get_stationary_variance(df_col, window_size);\n",
    "#     print(\">>> \", variance, noise.min(), noise.max());\n",
    "    threshold = sigmas_k * variance;\n",
    "    for n,v in enumerate(np.abs(noise)):\n",
    "        if(v > threshold):\n",
    "            df_col_res[n] = mean[n];\n",
    "    return df_col_res;\n",
    "\n",
    "def fix_bad_samples(ddf, window_size, sigmas_k):\n",
    "    result_df = pd.DataFrame();\n",
    "    result_df.index = ddf.index;\n",
    "    for colName in ddf.columns:\n",
    "        print(colName);\n",
    "        result_df[colName] = fix_bad_column_samples(ddf.loc[:, colName], window_size, sigmas_k);\n",
    "    return result_df;\n",
    "\n",
    "def normalize_data(df_fixed):\n",
    "    min_max={};\n",
    "    df_normalized = pd.DataFrame()\n",
    "    for n,colname in enumerate(df_fixed.columns):\n",
    "        row = df_fixed[colname];\n",
    "        row_min = row.min();\n",
    "        row_max = row.max();\n",
    "        df_normalized[colname] = (row - row_min) / (row_max - row_min);\n",
    "        min_max[colname]=[row_min, row_max];\n",
    "    df_normalized.index = list(range(0, df_fixed.shape[0]));\n",
    "    return df_normalized, min_max\n",
    "\n",
    "def denormalize_data(df_normalized, min_max):\n",
    "    df_denormalized = pd.DataFrame(columns = df_normalized.columns,index = df_normalized.index)\n",
    "\n",
    "    for n,colname in enumerate(df_normalized.columns):\n",
    "        row_min,row_max = min_max[colname]\n",
    "        scale = row_max - row_min\n",
    "        df_denormalized[colname] =  df_normalized[colname] * scale + row_min\n",
    "    return df_denormalized\n",
    "\n",
    "def re_normalize_data(df_fixed, min_max):\n",
    "    df_re_normalized = pd.DataFrame()\n",
    "   \n",
    "    for n,colname in enumerate(df_fixed.columns):\n",
    "        row_min, row_max = min_max[colname];\n",
    "        row = df_fixed[colname];\n",
    "        df_re_normalized[colname] = (row - row_min) / (row_max - row_min);\n",
    "\n",
    "#    df_re_normalized.index = list(range(0, df_fixed.shape[0]));  \n",
    "    df_re_normalized.index = df_fixed.index;  \n",
    "    return df_re_normalized, min_max\n",
    "    \n",
    "\n",
    "def copy_previous_for_nan (df):\n",
    "    last_incomplete_row = -1;\n",
    "    most_harmed_column = '';\n",
    "    rows_count, columns_count = df.shape;\n",
    "    for column in df.columns:\n",
    "        for row in range(rows_count):\n",
    "            if pd.isna(df.loc[row, column]):\n",
    "                try:\n",
    "                    previous_value = df.loc[row - 1, column];\n",
    "                    df.loc[row, column] = previous_value;\n",
    "                    if pd.isna(previous_value) and last_incomplete_row < row:\n",
    "                        last_incomplete_row = row;\n",
    "                        most_harmed_column = column;\n",
    "                except (KeyError, ValueError):\n",
    "                    continue;             \n",
    "    return (last_incomplete_row, most_harmed_column)\n",
    "    \n",
    "def prepare_data_to_concatenate(file_path, column_names):\n",
    "    df = pd.read_csv(file_path, delimiter = \",\", index_col=False).loc[:, column_names];\n",
    "    number, col_name = copy_previous_for_nan(df);\n",
    "    df = df[number+1:]; \n",
    "    df = set_timestamp_as_index(df);\n",
    "    df = df.resample('1T').mean();\n",
    "    df = pad_nans(df);  \n",
    "    return df\n",
    "\n",
    "def time_resampling(df, new_resampled_rate = '1T', ts_format = '%Y/%m/%d %H:%M:%S.%f'):\n",
    "    df1 = set_timestamp_as_index(df,ts_format = ts_format);\n",
    "    df1 = df1.resample(new_resampled_rate).mean();\n",
    "    df1 = pad_nans(df1);\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_segments_statistics(dfs, statistics_df = pd.DataFrame()):\n",
    "    dfs_result = []\n",
    "    for df in dfs:\n",
    "        df_tmp = get_single_segment_statistics(df)\n",
    "        dfs_result.append(df_tmp)\n",
    "    df = pd.concat(dfs_result); \n",
    "    df.index = list(range(0,df.shape[0]))\n",
    "    return df;\n",
    "\n",
    "def get_single_segment_statistics(df):\n",
    "    df1 = pd.DataFrame();\n",
    "    df1.loc[0,'Segment'] = df['Current segment'].values[0]\n",
    "    df1.loc[0,'Mass'] = df['Mass'].values[0]\n",
    "    df1.loc[0,'Samples count'] = df.shape[0]\n",
    "\n",
    "    tmp_column = pd.to_datetime(df['Timestamp'], format='%Y/%m/%d %H:%M:%S').values\n",
    "    t1 = pd.Timestamp(tmp_column[0]);\n",
    "    df1.loc[0,'Day hour'] = t1.hour #* 60 + t1.minute;\n",
    "    t_min = pd.Timestamp(tmp_column.min())\n",
    "    t_max = pd.Timestamp(tmp_column.max())\n",
    "    df1.loc[0,'Duration'] =(t_max-t_min).seconds\n",
    "    tmp_column = df['Battery cell voltage'].values\n",
    "    df1.loc[0,'Start segment voltage'] = tmp_column[0]\n",
    "    df1.loc[0,'End segment voltage'] = tmp_column[-1]\n",
    "    df1.loc[0,'Voltage delta'] = tmp_column[-1]-tmp_column[0]\n",
    "    return df1;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
